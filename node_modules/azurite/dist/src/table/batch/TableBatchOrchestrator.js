"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const BatchRequest_1 = tslib_1.__importDefault(require("../../common/batch/BatchRequest"));
const BatchTableInsertEntityOptionalParams_1 = tslib_1.__importDefault(require("./BatchTableInsertEntityOptionalParams"));
const TableStorageContext_1 = tslib_1.__importDefault(require("../context/TableStorageContext"));
const TableBatchSerialization_1 = require("./TableBatchSerialization");
const BatchTableDeleteEntityOptionalParams_1 = tslib_1.__importDefault(require("./BatchTableDeleteEntityOptionalParams"));
const BatchTableUpdateEntityOptionalParams_1 = tslib_1.__importDefault(require("./BatchTableUpdateEntityOptionalParams"));
const BatchTableMergeEntityOptionalParams_1 = tslib_1.__importDefault(require("./BatchTableMergeEntityOptionalParams"));
const BatchTableQueryEntitiesWithPartitionAndRowKeyOptionalParams_1 = tslib_1.__importDefault(require("./BatchTableQueryEntitiesWithPartitionAndRowKeyOptionalParams"));
const uuid_1 = require("uuid");
const StorageErrorFactory_1 = tslib_1.__importDefault(require("../errors/StorageErrorFactory"));
/**
 * Currently there is a single distinct and concrete implementation of batch /
 * entity group operations for the table api.
 * The orchestrator manages the deserialization, submission and serialization of
 * entity group transactions.
 * ToDo: it might be possible to share code between this and the blob batch api, but this
 * has not yet been validated.
 * Will need refactoring when we address batch transactions for blob.
 *
 * @export
 * @class TableBatchOrchestrator
 */
class TableBatchOrchestrator {
    constructor(context, handler) {
        this.batchOperations = [];
        this.requests = [];
        this.serialization = new TableBatchSerialization_1.TableBatchSerialization();
        this.wasError = false;
        this.errorResponse = "";
        this.context = context;
        this.parentHandler = handler;
    }
    /**
     * This is the central route / sequence of the batch orchestration.
     * Takes batchRequest body, deserializes requests, submits to handlers, then returns serialized response
     *
     * @param {string} batchRequestBody
     * @return {*}  {Promise<string>}
     * @memberof TableBatchManager
     */
    async processBatchRequestAndSerializeResponse(batchRequestBody, metadataStore) {
        this.batchOperations =
            this.serialization.deserializeBatchRequest(batchRequestBody);
        if (this.batchOperations.length > 100) {
            this.wasError = true;
            this.errorResponse = this.serialization.serializeGeneralRequestError("0:The batch request operation exceeds the maximum 100 changes per change set.", this.context.xMsRequestID);
        }
        else {
            await this.submitRequestsToHandlers(metadataStore);
        }
        return this.serializeResponses();
    }
    /**
     * Submits requests to the appropriate handlers
     * ToDo: Correct logic and handling of requests with Content ID
     *
     * @private
     * @return {*}  {Promise<void>}
     * @memberof TableBatchManager
     */
    async submitRequestsToHandlers(metadataStore) {
        var _a;
        var _b;
        this.batchOperations.forEach((operation) => {
            const request = new BatchRequest_1.default(operation);
            this.requests.push(request);
        });
        let contentID = 1;
        if (this.requests.length > 0) {
            const accountName = ((_a = (_b = this.context).account) !== null && _a !== void 0 ? _a : (_b.account = ""));
            const tableName = this.requests[0].getPath();
            const batchId = uuid_1.v4();
            // get partition key from the request body or uri to copy that specific partition of database
            const requestPartitionKey = this.extractRequestPartitionKey(this.requests[0]);
            if (requestPartitionKey === undefined) {
                this.wasError = true;
                this.errorResponse = this.serialization.serializeGeneralRequestError("Partition key not found in request", this.context.xMsRequestID);
            }
            else {
                // initialize transaction rollback capability
                await metadataStore.beginBatchTransaction(batchId);
            }
            let batchSuccess = true;
            for (const singleReq of this.requests) {
                try {
                    singleReq.response = await this.routeAndDispatchBatchRequest(singleReq, this.context, contentID, batchId);
                }
                catch (err) {
                    batchSuccess = false;
                    this.wasError = true;
                    this.errorResponse = this.serialization.serializeError(err, contentID, singleReq);
                    break;
                }
                contentID++;
            }
            await metadataStore.endBatchTransaction(accountName, tableName, batchId, this.context, batchSuccess);
        }
    }
    /**
     * Serializes responses from the table handler
     * see Link below for details of response format
     * tslint:disable-next-line: max-line-length
     * https://docs.microsoft.com/en-us/rest/api/storageservices/performing-entity-group-transactions#json-versions-2013-08-15-and-later-2
     *
     * @private
     * @return {*}  {string}
     * @memberof TableBatchManager
     */
    serializeResponses() {
        let responseString = "";
        // based on research, a stringbuilder is only worth doing with 1000s of string ops
        // this can be optimized later if we get reports of slow batch operations
        const batchBoundary = this.serialization.batchBoundary.replace("batch", "batchresponse");
        let changesetBoundary = this.serialization.changesetBoundary.replace("changeset", "changesetresponse");
        responseString += batchBoundary + "\r\n";
        // (currently static header) ToDo: Validate if we need to correct headers via tests
        responseString +=
            "Content-Type: multipart/mixed; boundary=" + changesetBoundary + "\r\n";
        const changesetBoundaryClose = "\r\n--" + changesetBoundary + "--\r\n";
        changesetBoundary = "\r\n--" + changesetBoundary;
        if (this.wasError === false) {
            this.requests.forEach((request) => {
                responseString += changesetBoundary;
                responseString += request.response;
                responseString += "\r\n\r\n";
            });
        }
        else {
            // serialize the error
            responseString += changesetBoundary + "\r\n";
            // then headers
            responseString += "Content-Type: application/http\r\n";
            responseString += "Content-Transfer-Encoding: binary\r\n";
            responseString += "\r\n";
            // then HTTP/1.1 404 etc
            responseString += this.errorResponse;
        }
        responseString += changesetBoundaryClose;
        responseString += batchBoundary + "--\r\n";
        return responseString;
    }
    /**
     * Routes and dispatches single operations against the table handler and stores
     * the serialized result.
     *
     * @private
     * @param {BatchRequest} request
     * @param {Context} context
     * @param {number} contentID
     * @return {*}  {Promise<any>}
     * @memberof TableBatchManager
     */
    async routeAndDispatchBatchRequest(request, context, contentID, batchId) {
        // the context that we have will not work with the calls and needs updating for
        // batch operations, need a suitable deep clone, as each request needs to be treated seaprately
        const batchContextClone = Object.create(context);
        batchContextClone.tableName = request.getPath();
        batchContextClone.path = request.getPath();
        let response;
        let __return;
        // we only use 5 HTTP Verbs to determine the table operation type
        try {
            switch (request.getMethod()) {
                case "POST":
                    // INSERT: we are inserting an entity
                    // POST	https://myaccount.table.core.windows.net/mytable
                    ({ __return, response } = await this.handleBatchInsert(request, response, batchContextClone, contentID, batchId));
                    break;
                case "PUT":
                    // UPDATE: we are updating an entity
                    // PUT http://127.0.0.1:10002/devstoreaccount1/mytable(PartitionKey='myPartitionKey', RowKey='myRowKey')
                    // INSERT OR REPLACE:
                    // PUT	https://myaccount.table.core.windows.net/mytable(PartitionKey='myPartitionKey', RowKey='myRowKey')
                    ({ __return, response } = await this.handleBatchUpdate(request, response, batchContextClone, contentID, batchId));
                    break;
                case "DELETE":
                    // DELETE: we are deleting an entity
                    // DELETE	https://myaccount.table.core.windows.net/mytable(PartitionKey='myPartitionKey', RowKey='myRowKey')
                    ({ __return, response } = await this.handleBatchDelete(request, response, batchContextClone, contentID, batchId));
                    break;
                case "GET":
                    // QUERY : we are querying / retrieving an entity
                    // GET	https://myaccount.table.core.windows.net/mytable(PartitionKey='<partition-key>',RowKey='<row-key>')?$select=<comma-separated-property-names>
                    ({ __return, response } = await this.handleBatchQuery(request, response, batchContextClone, contentID, batchId));
                    break;
                case "CONNECT":
                    throw new Error("Connect Method unsupported in batch.");
                    break;
                case "HEAD":
                    throw new Error("Head Method unsupported in batch.");
                    break;
                case "OPTIONS":
                    throw new Error("Options Method unsupported in batch.");
                    break;
                case "TRACE":
                    throw new Error("Trace Method unsupported in batch.");
                    break;
                case "PATCH":
                    // this is using the PATCH verb to merge
                    ({ __return, response } = await this.handleBatchMerge(request, response, batchContextClone, contentID, batchId));
                    break;
                default:
                    // MERGE: this must be the merge, as the merge operation is not currently generated by autorest
                    // MERGE	https://myaccount.table.core.windows.net/mytable(PartitionKey='myPartitionKey', RowKey='myRowKey')
                    // INSERT OR MERGE
                    // MERGE	https://myaccount.table.core.windows.net/mytable(PartitionKey='myPartitionKey', RowKey='myRowKey')
                    ({ __return, response } = await this.handleBatchMerge(request, response, batchContextClone, contentID, batchId));
            }
        }
        catch (batchException) {
            // this allows us to catch and debug any errors in the batch handling
            throw batchException;
        }
        return __return;
    }
    /**
     * Handles an insert operation inside a batch
     *
     * @private
     * @param {BatchRequest} request
     * @param {*} response
     * @param {*} batchContextClone
     * @param {number} contentID
     * @return {*}  {Promise<{
     *     __return: string;
     *     response: any;
     *   }>}
     * @memberof TableBatchManager
     */
    async handleBatchInsert(request, response, batchContextClone, contentID, batchId) {
        request.ingestOptionalParams(new BatchTableInsertEntityOptionalParams_1.default());
        const updatedContext = new TableStorageContext_1.default(batchContextClone);
        updatedContext.request = request;
        updatedContext.batchId = batchId;
        response = await this.parentHandler.insertEntity(request.getPath(), request.params, updatedContext);
        return {
            __return: this.serialization.serializeTableInsertEntityBatchResponse(request, response),
            response
        };
    }
    /**
     * Handles a delete Operation inside a batch request
     *
     * @private
     * @param {BatchRequest} request
     * @param {*} response
     * @param {*} batchContextClone
     * @param {number} contentID
     * @return {*}  {Promise<{
     *     __return: string;
     *     response: any;
     *   }>}
     * @memberof TableBatchManager
     */
    async handleBatchDelete(request, response, batchContextClone, contentID, batchId) {
        request.ingestOptionalParams(new BatchTableDeleteEntityOptionalParams_1.default());
        const updatedContext = batchContextClone;
        updatedContext.request = request;
        updatedContext.batchId = batchId;
        const ifmatch = request.getHeader("if-match") || "*";
        const partitionKey = this.extractRequestPartitionKey(request);
        const rowKey = this.extractRequestRowKey(request);
        response = await this.parentHandler.deleteEntity(request.getPath(), partitionKey, rowKey, ifmatch, request.params, updatedContext);
        return {
            __return: this.serialization.serializeTableDeleteEntityBatchResponse(request, response),
            response
        };
    }
    /**
     * Handles an update Operation inside a batch request
     *
     * @private
     * @param {BatchRequest} request
     * @param {*} response
     * @param {*} batchContextClone
     * @param {number} contentID
     * @return {*}  {Promise<{
     *     __return: string;
     *     response: any;
     *   }>}
     * @memberof TableBatchManager
     */
    async handleBatchUpdate(request, response, batchContextClone, contentID, batchId) {
        request.ingestOptionalParams(new BatchTableUpdateEntityOptionalParams_1.default());
        const updatedContext = batchContextClone;
        updatedContext.request = request;
        updatedContext.batchId = batchId;
        const partitionKey = this.extractRequestPartitionKey(request);
        const rowKey = this.extractRequestRowKey(request);
        const ifmatch = request.getHeader("if-match") || "*";
        response = await this.parentHandler.updateEntity(request.getPath(), partitionKey, rowKey, Object.assign({ ifMatch: ifmatch }, request.params), updatedContext);
        return {
            __return: this.serialization.serializeTableUpdateEntityBatchResponse(request, response),
            response
        };
    }
    /**
     * Handles a query operation inside a batch request,
     * should only ever be one operation if there is a query
     *
     * @private
     * @param {BatchRequest} request
     * @param {*} response
     * @param {*} batchContextClone
     * @param {number} contentID
     * @return {*}  {Promise<{
     *     __return: string;
     *     response: any;
     *   }>}
     * @memberof TableBatchManager
     */
    async handleBatchQuery(request, response, batchContextClone, contentID, batchId) {
        // need to validate that query is the only request in the batch!
        const partitionKey = this.extractRequestPartitionKey(request);
        const rowKey = this.extractRequestRowKey(request);
        const updatedContext = batchContextClone;
        updatedContext.batchId = batchId;
        if (null !== partitionKey &&
            null !== rowKey &&
            partitionKey !== "" &&
            rowKey !== "") {
            // ToDo: this is hideous... but we need the params on the request object,
            // as they percolate through and are needed for the final serialization
            // currently, because of the way we deconstruct / deserialize, we only
            // have the right model at a very late stage in processing
            // this might resolve when we simplify Query logic
            // based on only accepting Query with partition and row key
            request.ingestOptionalParams(new BatchTableQueryEntitiesWithPartitionAndRowKeyOptionalParams_1.default());
            updatedContext.request = request;
            response = await this.parentHandler.queryEntitiesWithPartitionAndRowKey(request.getPath(), partitionKey, rowKey, request.params, updatedContext);
            return {
                __return: await this.serialization.serializeTableQueryEntityWithPartitionAndRowKeyBatchResponse(request, response),
                response
            };
        }
        else {
            throw StorageErrorFactory_1.default.getNotImplementedError(batchContextClone);
        }
    }
    /**
     * Handles a merge operation inside a batch request
     *
     * @private
     * @param {BatchRequest} request
     * @param {*} response
     * @param {*} batchContextClone
     * @param {number} contentID
     * @return {*}  {Promise<{
     *     __return: string;
     *     response: any;
     *   }>}
     * @memberof TableBatchManager
     */
    async handleBatchMerge(request, response, batchContextClone, contentID, batchId) {
        request.ingestOptionalParams(new BatchTableMergeEntityOptionalParams_1.default());
        const updatedContext = batchContextClone;
        updatedContext.request = request;
        updatedContext.batchId = batchId;
        const partitionKey = this.extractRequestPartitionKey(request);
        const rowKey = this.extractRequestRowKey(request);
        const ifmatch = request.getHeader("if-match") || "*";
        response = await this.parentHandler.mergeEntity(request.getPath(), partitionKey, rowKey, Object.assign({ ifMatch: ifmatch }, request.params), updatedContext);
        return {
            __return: this.serialization.serializeTablMergeEntityBatchResponse(request, response),
            response
        };
    }
    /**
     * extracts the Partition key from a request
     *
     * @private
     * @param {BatchRequest} request
     * @return {*}  {string}
     * @memberof TableBatchOrchestrator
     */
    extractRequestPartitionKey(request) {
        let partitionKey;
        const url = decodeURI(request.getUrl());
        const partKeyMatch = url.match(/(?<=PartitionKey=')(.*)(?=',)/gi);
        if (partKeyMatch === null) {
            // row key not in URL, must be in body
            const body = request.getBody();
            if (body !== "") {
                const jsonBody = JSON.parse(body ? body : "{}");
                partitionKey = jsonBody.PartitionKey;
            }
        }
        else {
            // keys can have more complex values which are URI encoded
            partitionKey = decodeURIComponent(partKeyMatch[0]);
        }
        return partitionKey;
    }
    /**
     * Helper function to extract values needed for handler calls
     *
     * @private
     * @param {BatchRequest} request
     * @return { string }
     * @memberof TableBatchManager
     */
    extractRequestRowKey(request) {
        let rowKey;
        const url = decodeURI(request.getUrl());
        const rowKeyMatch = url.match(/(?<=RowKey=')(.+)(?='\))/gi);
        rowKey = rowKeyMatch ? rowKeyMatch[0] : "";
        if (rowKey === "") {
            // row key not in URL, must be in body
            const body = request.getBody();
            if (body !== "") {
                const jsonBody = JSON.parse(body ? body : "{}");
                rowKey = jsonBody.RowKey;
            }
        }
        else {
            // keys can have more complex values which are URI encoded
            rowKey = decodeURIComponent(rowKey);
        }
        return rowKey;
    }
}
exports.default = TableBatchOrchestrator;
//# sourceMappingURL=TableBatchOrchestrator.js.map